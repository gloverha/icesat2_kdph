{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaeebceb-4eeb-4e6c-90f0-be6360b21969",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The goal is to find matching ICESat-2 ATL03 photon data matching the times and lat/lon of the published Kd values from BGC ARGO floats (10.5281/zenodo.8228242). \n",
    "\n",
    "The Kd CSV file was edited after download from Zenodo. Kd calculations were sorted by date. This pre-processing could jsut as easily be done in python but I already had the csv open to look at the contents. Edited version is called Dataset_Kd_Paper_2018. \n",
    "\n",
    "Actions:\n",
    "- Load lat/lon and time for each Kd calculation\n",
    "- Check if there is a matching pass for ICESat-2 within +- x hours and  x km.\n",
    "- The notebook saves pickle files of GeoDataFrames (pandas), appending the matching row of the spreadsheet of latlontimes. \n",
    "- These GDFs are the output of the icesat2.atl03sp search function. The contents of each GDF can be found here: https://slideruleearth.io/web/rtd/user_guide/ICESat-2.html#photon-segments\n",
    "- Also saves a new copy of Dataset_Kd_Paper_2018_dep with only the matching kd rows.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2256384a-86a8-43c0-801b-5953747525ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet rtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a80715-bdf2-45ce-afe9-9fa0f0bd7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f821b93-0ec9-41db-af0e-61e26934504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icepyx as ipx\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import workspace_path, atl03_path,\\\n",
    "                 other_data_path ,shoreline_data ,gebco_path ,\\\n",
    "                 horizontal_res ,vertical_res ,subsurface_thresh ,\\\n",
    "                 ignore_subsurface_height_thres ,output_path \n",
    "\n",
    "\n",
    "    \n",
    "from kd_utils.data_processing import load_data, \\\n",
    "                                    extract_file_params, \\\n",
    "                                    Extract_sea_photons, \\\n",
    "                                    filter_photon_dataset_by_hull_area\n",
    "    \n",
    "from kd_utils.sea_photons_analysis import process_sea_photon_binning,\\\n",
    "                            get_sea_surface_height\n",
    "                            \n",
    "                            \n",
    "from kd_utils.bathy_processing import process_subsurface_photon_filtering\n",
    "\n",
    "from kd_utils.visualization import plot_photon_height, \\\n",
    "                                   plot_kd_photons, \\\n",
    "                                   plot_filtered_seafloor_photons\n",
    "                                   \n",
    "from kd_utils.Kd_analysis import process_kd_calculation\n",
    "\n",
    "from kd_utils.interpolation import geoid_correction, \\\n",
    "                                    refraction_correction, \\\n",
    "                                    interpolate_labels, \\\n",
    "                                    apply_interpolation\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ae97e48-47cb-461e-ac38-1f4ca6df96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buoy_bound_box(lat,lon,buffer_km):\n",
    "    # define a buffer distance around the buoy to search for icesat-2 data\n",
    "    lat_buff = buffer_km/111 # convert buffer distance to frac of 1 deg lat\n",
    "    lon_buff = buffer_km/(111*np.cos(lat*np.pi/180)) # convert buffer distance to frac of 1 deg lon\n",
    "    # define bounding box around the buoy (WSEN)\n",
    "    # example: bbox = [-108.3, 39.2, -107.8, 38.8]\n",
    "    # bbox = [lon-lon_buff,lat+lat_buff,lon+lon_buff,lat-lat_buff]\n",
    "    # region = sliderule.toregion(bbox)\n",
    "    minx = lon - lon_buff\n",
    "    miny = lat - lat_buff\n",
    "    maxx = lon + lon_buff\n",
    "    maxy = lat + lat_buff\n",
    "\n",
    "    # polygon vertices: Given as longitude, latitude coordinate pairs of decimal degrees with the last entry a repeat of the first.\n",
    "    poly = [(minx, miny), (maxx, miny), (maxx, maxy), (minx, maxy), (minx, miny)]\n",
    "\n",
    "    return poly\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        \n",
    "        # Load IS2 and extract sea photons\n",
    "        IS2_atl03_mds, IS2_atl03_attrs, IS2_atl03_beams = load_data(ATL03_h5_file_path)  \n",
    "        \n",
    "        ## For debugging\n",
    "        #IS2_atl03_beams=['gt1r']\n",
    "        \n",
    "        # Check beam types and ensure we have what we want (e.g., strong beams)\n",
    "        target_beam_type=['gt1l', 'gt2l', 'gt3l']        \n",
    "        IS2_atl03_beams = [beam for beam in IS2_atl03_beams if beam in target_beam_type]\n",
    "        if not IS2_atl03_beams:\n",
    "            print('No Strong Beam')\n",
    "            # sys.exit()  # Terminate the program\n",
    "        else:\n",
    "            print(f'Strong Beams Found: {IS2_atl03_beams}')\n",
    "        \n",
    "            # Extract sea photon by applying the land mask\n",
    "            sea_photon_dataset = Extract_sea_photons(IS2_atl03_mds, IS2_atl03_beams, shoreline_data_path)\n",
    "        \n",
    "        \n",
    "            # Main processing function to apply binning beam-by-beam \n",
    "            # to bin the photons data by vertical_res 25 cm and horizontal resolution 500m\n",
    "            binned_dataset_sea_surface = process_sea_photon_binning(sea_photon_dataset, horizontal_res=horizontal_res, vertical_res=vertical_res)\n",
    "                    \n",
    "        \n",
    "            # filter to get subsurface photons\n",
    "            sea_surface_height, sea_surface_label, filtered_seafloor_subsurface_photon_dataset = \\\n",
    "                process_subsurface_photon_filtering(binned_dataset_sea_surface, subsurface_thresh, GEBCO_file_path_lists)\n",
    "        \n",
    "            \n",
    "            # Visualization of the filtered seafloor photons\n",
    "            # Uncomment the following lines to visualize if needed\n",
    "            # output_path = OutputPath+'/IS2_subsurface_RM_Seafloor.jpg'\n",
    "            # plot_filtered_seafloor_photons(filtered_seafloor_subsurface_dataset=filtered_seafloor_subsurface_photon_dataset, \n",
    "            #                                 sea_photon_dataset=sea_photon_dataset, \n",
    "            #                                 sea_surface_height=sea_surface_height, \n",
    "            #                                 output_path=output_path)\n",
    "        \n",
    "            ########################\n",
    "            # Todo: move the filter to the begining\n",
    "            # Filter shallow photons that may have noises from wave, afterpulse, or others\n",
    "            # by setting Ignore_Subsurface_Height_Thres (i.e., -6)\n",
    "            # Masked out the deep water photons by applying (filtered_seafloor_subsurface_photon_dataset < Ignore_Subsurface_Height_Thres)\n",
    "            # Filter out points below the seafloor\n",
    "            Final_filtered_subsurface_photon_dataset = filtered_seafloor_subsurface_photon_dataset[\n",
    "                filtered_seafloor_subsurface_photon_dataset['photon_height'] < Ignore_Subsurface_Height_Thres\n",
    "            ]\n",
    "            \n",
    "            # Final_filtered_subsurface_photon_dataset = filtered_seafloor_subsurface_photon_dataset\n",
    "                   \n",
    "            #Filter dataframe based on beam list\n",
    "            Final_filtered_subsurface_photon_dataset = Final_filtered_subsurface_photon_dataset[Final_filtered_subsurface_photon_dataset['beam_id'].isin(target_beam_type)]\n",
    "            \n",
    "            ###################################\n",
    "            ### Todo: move the filter to the begining\n",
    "            # Steps to standardize KD calculation by filtering out \n",
    "            # segments lacking sufficient subsurface photons.\n",
    "            # Approach: Use the ConvexHull of photons within \n",
    "            # each rectanglar area formed by each horizontal bin (here, it is lat_bins) and \n",
    "            # based on dataframe Final_filtered_subsurface_photon_dataset along the distance of the track\n",
    "        \n",
    "            # Apply filtering based on hull area if desired\n",
    "            Final_filtered_subsurface_photon_dataset, convex_hull_areas, convex_hulls = filter_photon_dataset_by_hull_area(\n",
    "                Final_filtered_subsurface_photon_dataset, hull_area_threshold=1500\n",
    "            )\n",
    "            \n",
    "            # Visualization\n",
    "            # Uncomment the following line to visualize if needed\n",
    "            \n",
    "            # plot_target_beam=['gt1l']\n",
    "            # plot_convex_hulls(Final_filtered_subsurface_photon_dataset, plot_target_beam, convex_hulls, convex_hull_areas)\n",
    "            \n",
    "            ########################################### \n",
    "            # calculate kd and save it to table\n",
    "            SubsurfacePhotonDFAddedKd = process_kd_calculation(Final_filtered_subsurface_photon_dataset)\n",
    "        \n",
    "        \n",
    "            ## Todo move this part into a function so that it will not looks too busy here\n",
    "            # Extract the timestamp using regex and use it to set the output file name\n",
    "            match = re.search(r\"_(\\d{14})_\", ATL03_h5_file_path)\n",
    "            timestamp = match.group(1) if match else \"unknown\"\n",
    "            \n",
    "            output_file_path = os.path.join(OutputPath, f\"{timestamp}_AddedKdDataset_strongBeams_Further.csv\")\n",
    "            SubsurfacePhotonDFAddedKd.to_csv(output_file_path, index=False)\n",
    "        \n",
    "            if 'relative_AT_dist' in filtered_seafloor_subsurface_photon_dataset.columns:\n",
    "                unique_photon_dataset = filtered_seafloor_subsurface_photon_dataset[['relative_AT_dist', 'lat_bins', 'photon_height']].drop_duplicates()\n",
    "                unique_photon_dataset['relative_AT_dist_center'] = unique_photon_dataset\\\n",
    "                                        .groupby('lat_bins', observed=False)['relative_AT_dist'].transform('mean')\n",
    "                def find_closest(group):\n",
    "                    if not group.empty:\n",
    "                        center = group['relative_AT_dist_center'].iloc[0]\n",
    "                        group['dist_to_center'] = abs(group['relative_AT_dist'] - center)\n",
    "                        closest_index = group['dist_to_center'].idxmin()\n",
    "                        return group.loc[[closest_index]]\n",
    "                    else:\n",
    "                        return pd.DataFrame(columns=group.columns)\n",
    "                \n",
    "                # Filter out empty or all-NA entries\n",
    "                unique_photon_dataset_filtered = unique_photon_dataset.dropna(how='all', axis=1)\n",
    "        \n",
    "                # Group by 'lat_bins' and apply the find_closest function\n",
    "                closest_to_center = unique_photon_dataset_filtered\\\n",
    "                                        .groupby('lat_bins', observed=False)\\\n",
    "                                        .apply(find_closest, include_groups=True)\n",
    "                                        # .reset_index()\n",
    "                                        \n",
    "                # Remove the index without resetting it if 'lat_bins' already exists\n",
    "                closest_to_center.index = closest_to_center.index.droplevel(0)\n",
    "            \n",
    "                # Ensure relevant entries are excluded before concatenation\n",
    "                closest_to_center = closest_to_center.dropna(axis=1, how='all')\n",
    "            \n",
    "                Kd_DF_MergedDistance = closest_to_center.merge(SubsurfacePhotonDFAddedKd, on='lat_bins', how='left')\n",
    "                Kd_DF_MergedDistance = Kd_DF_MergedDistance.drop(columns=['relative_AT_dist_center', 'dist_to_center'])\n",
    "                \n",
    "                \n",
    "                # plot_kd_photons(OutputPath, timestamp, plot_target_beam, filtered_seafloor_subsurface_photon_dataset, Kd_DF_MergedDistance)\n",
    "        \n",
    "            logging.info(\"SUCCESS!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "            logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     # Get arguments function\n",
    "#     args = get_args()    \n",
    "   \n",
    "#     ATL03_h5_file_path = os.path.join(args.workspace_path, args.atl03_path, args.atl03_file)\n",
    "    \n",
    "#     shoreline_data_path = os.path.join(args.workspace_path, args.other_data_path, args.shoreline_data)\n",
    "    \n",
    "#     GEBCO_full_path = os.path.join(args.workspace_path, args.other_data_path, args.gebco_path)\n",
    "    \n",
    "#     OutputPath = os.path.join(args.workspace_path, args.output_path)\n",
    "    \n",
    "#     #Get the gebco list\n",
    "#     #gebco_2024_n0.0_s-90.0_w0.0_e90.0.tif\n",
    "#     GEBCO_file_pattern = os.path.join(GEBCO_full_path, \"gebco_*.tif\")\n",
    "\n",
    "#     #Initialize with an empty list\n",
    "#     GEBCO_file_path_lists = []\n",
    "#     for GEBCO_file_path_name in glob.glob(GEBCO_file_pattern):\n",
    "#         #put the find one into the list\n",
    "#         GEBCO_file_path_lists.append(GEBCO_file_path_name)\n",
    "\n",
    "    \n",
    "#     # Get all other necessary parameters\n",
    "#     horizontal_res = args.horizontal_res\n",
    "    \n",
    "#     vertical_res = args.vertical_res\n",
    "    \n",
    "#     subsurface_thresh = args.subsurface_thresh\n",
    "    \n",
    "#     Ignore_Subsurface_Height_Thres = args.ignore_subsurface_height_thres\n",
    "    \n",
    "#     # When all paramters ready, call the main function\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d72dbef-f954-499f-be76-c1de3233b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time, lat and lon\n",
    "df = pd.read_csv(\"data/Dataset_Kd_Paper_2018.csv\")\n",
    "# convert matlab time to datetime objects\n",
    "df[\"dt_float\"] = pd.to_datetime(df[\"dt_float\"]-719529,unit='d',utc=True).round('s')\n",
    "# remove all rows from before icesat2 launched\n",
    "df = df[df[\"dt_float\"]>datetime.fromisoformat('2018-10-01T00:00:00Z')]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cbc4d3-802a-4e98-9220-8b847742bc3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 100/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  gloverha\n",
      "Enter your Earthdata password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order ID:  5000005875967\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875967 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875968\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875968 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875969\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875969 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 200/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875970\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875970 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 300/5129\n",
      "processing 400/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875971\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875971 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875972\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875972 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 500/5129\n",
      "processing 600/5129\n",
      "processing 700/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875973\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875973 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875974\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875974 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875975\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875975 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875976\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875976 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875977\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875977 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 800/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875978\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875978 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 900/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875979\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875979 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875980\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875980 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1000/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875981\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875981 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875982\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875982 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875983\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875983 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875984\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875984 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1100/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875985\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875985 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875986\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875986 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875987\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875987 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875988\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875988 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1200/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875989\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875989 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1500/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875991\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875991 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875992\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875992 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1600/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875993\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875993 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875994\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875994 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1700/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875995\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875995 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875996\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875996 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 1800/5129\n",
      "processing 1900/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875997\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875997 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875998\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875998 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005875999\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005875999 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 2000/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876000\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876000 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876001\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876001 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876002\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876002 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876003\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876003 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876004\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876004 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 2100/5129\n",
      "processing 2200/5129\n",
      "processing 2300/5129\n",
      "processing 2400/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876005\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876005 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876006\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876006 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876007\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876007 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 2500/5129\n",
      "processing 2600/5129\n",
      "processing 2700/5129\n",
      "processing 2800/5129\n",
      "processing 2900/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876008\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876008 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876009\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876009 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876010\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876010 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876011\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876011 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 3000/5129\n",
      "processing 3100/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876012\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876012 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876013\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876013 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 3200/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876014\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876014 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876015\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876015 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876016\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876016 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 3300/5129\n",
      "processing 3400/5129\n",
      "processing 3500/5129\n",
      "processing 3600/5129\n",
      "processing 3700/5129\n",
      "processing 3800/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876018\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876018 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876019\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876019 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876021\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876021 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876022\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876022 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876023\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876023 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876024\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876024 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876025\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876025 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876026\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876026 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876027\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876027 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 3900/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876028\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876028 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876029\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876029 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 4000/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876030\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876030 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 4100/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876031\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876031 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876032\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876032 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876033\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876033 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876034\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876034 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 4200/5129\n",
      "processing 4300/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876035\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876035 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876036\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876036 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 4400/5129\n",
      "processing 4500/5129\n",
      "processing 4600/5129\n",
      "processing 4700/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876037\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876037 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876038\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876038 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876039\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876039 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876040\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876040 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876041\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876041 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876042\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876042 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876043\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876043 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 4800/5129\n",
      "processing 4900/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876044\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876044 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876045\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876045 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876046\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876046 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876047\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876047 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876048\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876048 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876049\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876049 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 5000/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876050\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876050 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876051\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876051 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  2  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876052\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876052 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "Total number of data order requests is  1  for  2  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876053\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876053 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "processing 5100/5129\n",
      "Total number of data order requests is  1  for  1  granules.\n",
      "Data request  1  of  1  is submitting to NSIDC\n",
      "order ID:  5000005876054\n",
      "Initial status of your order request at NSIDC is:  processing\n",
      "Your order status is still  processing  at NSIDC. Please continue waiting... this may take a few moments.\n",
      "Your order is: complete\n",
      "Beginning download of zipped output...\n",
      "Data request 5000005876054 of  1  order(s) is downloaded.\n",
      "Download complete\n",
      "success\n",
      "5129\n"
     ]
    }
   ],
   "source": [
    "df[\"check_sum\"] = False\n",
    "# these values can be adjusted to broaden/narrow the fit btwn icesat-2 and the ground truth\n",
    "search_hrs = 12\n",
    "search_km = 4\n",
    "for jj in range(100,len(df)):\n",
    "    if jj % 100 ==0:\n",
    "        print('processing '+str(jj) +'/'+str(len(df)))# give a printout every 100 for my sanity\n",
    "    # define a search region around the buoy \n",
    "    lat = df['lat_float'][jj]\n",
    "    lon = df['lon_float'][jj]\n",
    "    \n",
    "    spatial_extent = buoy_bound_box(lat,lon,search_km)\n",
    "    t_start = (df['dt_float'][jj]-timedelta(hours=search_hrs))\n",
    "    t_end = (df['dt_float'][jj]+timedelta(hours=search_hrs))\n",
    "    short_name = 'ATL03'\n",
    "    date_range = [t_start,t_end]\n",
    "    region = ipx.Query(short_name, spatial_extent, date_range)\n",
    "    try:\n",
    "        region.download_granules('data/')\n",
    "        print('success')\n",
    "        df[\"check_sum\"] = True# if data exists and is downloaded - note in the argo csv \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "\n",
    "# df = pd.read_pickle('glider_matches.pkl')\n",
    "df=df[df[\"check_sum\"]==True]\n",
    "print(len(df))\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "df.to_csv('results/Dataset_Kd_Paper_2018_dep_4km12h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e91ffef-8a80-4cbe-ac5b-3fd2c41e4842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:01,671 - INFO - ./data/processed_ATL03_20221110022321_07691706_006_01.h5\n",
      "2024-12-03 21:36:01,678 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:45,615 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:36:45,616 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:36:45,677 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:36:45,678 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:36:45,770 - INFO - SUCCESS!\n",
      "2024-12-03 21:36:45,780 - INFO - ./data/processed_ATL03_20220228153332_10441406_006_01.h5\n",
      "2024-12-03 21:36:45,786 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:36:46,193 - INFO - ./data/processed_ATL03_20181031050117_04970112_006_02.h5\n",
      "2024-12-03 21:36:46,200 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:46,764 - INFO - ./data/processed_ATL03_20210918222329_13331206_006_02.h5\n",
      "2024-12-03 21:36:46,770 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:47,193 - INFO - ./data/processed_ATL03_20190521030409_08070308_006_02.h5\n",
      "2024-12-03 21:36:47,203 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:37:29,816 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:37:29,817 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:37:29,862 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:37:29,862 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:37:29,941 - INFO - SUCCESS!\n",
      "2024-12-03 21:37:29,952 - INFO - ./data/processed_ATL03_20210220082739_08911006_006_01.h5\n",
      "2024-12-03 21:37:29,958 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:37:30,599 - INFO - ./data/processed_ATL03_20190626024324_13570302_006_02.h5\n",
      "2024-12-03 21:37:30,605 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt3l']\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:37:51,300 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:37:51,301 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:37:51,405 - INFO - SUCCESS!\n",
      "2024-12-03 21:37:51,417 - INFO - ./data/processed_ATL03_20210101105852_01291006_006_01.h5\n",
      "2024-12-03 21:37:51,423 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:37:51,893 - INFO - ./data/processed_ATL03_20200210023858_06930606_006_01.h5\n",
      "2024-12-03 21:37:51,899 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:37:52,652 - INFO - ./data/processed_ATL03_20221130045019_10761706_006_02.h5\n",
      "2024-12-03 21:37:52,658 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt2l']\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:38:13,287 - ERROR - An error occurred: zero-size array to reduction operation minimum which has no identity\n",
      "2024-12-03 21:38:13,330 - INFO - ./data/processed_ATL03_20220821205409_09311602_006_01.h5\n",
      "2024-12-03 21:38:13,336 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l']\n",
      "Processing strong beam: gt1l\n",
      "Processing binning for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt1l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:38:34,420 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:38:34,421 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:38:34,509 - INFO - SUCCESS!\n",
      "2024-12-03 21:38:34,519 - INFO - ./data/processed_ATL03_20220903094331_11221608_006_01.h5\n",
      "2024-12-03 21:38:34,526 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:39:16,009 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:39:16,009 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:39:16,048 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:39:16,048 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:39:16,139 - INFO - SUCCESS!\n",
      "2024-12-03 21:39:16,148 - INFO - ./data/processed_ATL03_20210216000557_08241014_006_01.h5\n",
      "2024-12-03 21:39:16,156 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:39:58,212 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:39:58,212 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:39:58,271 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:39:58,272 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:39:58,353 - INFO - SUCCESS!\n",
      "2024-12-03 21:39:58,363 - INFO - ./data/processed_ATL03_20230131135652_06421801_006_02.h5\n",
      "2024-12-03 21:39:58,371 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l', 'gt3l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:41:00,434 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:41:00,434 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:41:00,491 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:41:00,492 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:41:00,549 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:41:00,549 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:41:00,640 - INFO - SUCCESS!\n",
      "2024-12-03 21:41:00,652 - INFO - ./data/processed_ATL03_20230121145754_04891814_006_02.h5\n",
      "2024-12-03 21:41:00,658 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:41:42,085 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:41:42,086 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:41:42,147 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:41:42,148 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:41:42,239 - INFO - SUCCESS!\n",
      "2024-12-03 21:41:42,250 - INFO - ./data/processed_ATL03_20191107102440_06340507_006_01.h5\n",
      "2024-12-03 21:41:42,256 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1r', 'gt2r', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:41:42,787 - INFO - ./data/processed_ATL03_20200219140630_08380602_006_01.h5\n",
      "2024-12-03 21:41:42,796 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:41:43,382 - INFO - ./data/processed_ATL03_20221205162609_11601702_006_02.h5\n",
      "2024-12-03 21:41:43,388 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt1l']\n",
      "Processing strong beam: gt1l\n",
      "Processing binning for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt1l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:42:04,851 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:42:04,852 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:42:04,949 - INFO - SUCCESS!\n",
      "2024-12-03 21:42:04,963 - INFO - ./data/processed_ATL03_20190902114623_10140406_006_02.h5\n",
      "2024-12-03 21:42:04,975 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:42:05,398 - INFO - ./data/processed_ATL03_20190329173700_00070306_006_02.h5\n",
      "2024-12-03 21:42:05,404 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:42:46,983 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:42:46,984 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:42:47,005 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:42:47,005 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:42:47,090 - INFO - SUCCESS!\n",
      "2024-12-03 21:42:47,100 - INFO - ./data/processed_ATL03_20211014091744_03351302_006_01.h5\n",
      "2024-12-03 21:42:47,106 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l']\n",
      "Processing strong beam: gt1l\n",
      "Processing binning for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt1l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:43:08,855 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:43:08,855 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:43:08,958 - INFO - SUCCESS!\n",
      "2024-12-03 21:43:08,972 - INFO - ./data/processed_ATL03_20210804125607_06401202_006_01.h5\n",
      "2024-12-03 21:43:08,979 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:43:50,667 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:43:50,668 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:43:50,728 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:43:50,728 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:43:50,821 - INFO - SUCCESS!\n",
      "2024-12-03 21:43:50,833 - INFO - ./data/processed_ATL03_20190613015947_11580302_006_02.h5\n",
      "2024-12-03 21:43:50,839 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:44:32,360 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:44:32,361 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:44:32,415 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:44:32,415 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:44:32,502 - INFO - SUCCESS!\n",
      "2024-12-03 21:44:32,512 - INFO - ./data/processed_ATL03_20201020040408_03970902_006_01.h5\n",
      "2024-12-03 21:44:32,518 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:45:13,542 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:45:13,542 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:45:13,561 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:45:13,561 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:45:13,648 - INFO - SUCCESS!\n",
      "2024-12-03 21:45:13,661 - INFO - ./data/processed_ATL03_20230131140354_06421802_006_02.h5\n",
      "2024-12-03 21:45:13,666 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:45:14,087 - INFO - ./data/processed_ATL03_20220126040658_05331402_006_01.h5\n",
      "2024-12-03 21:45:14,093 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt1l', 'gt2l', 'gt3l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:46:17,054 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:46:17,055 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:46:17,088 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:46:17,088 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:46:17,124 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:46:17,125 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:46:17,166 - INFO - SUCCESS!\n",
      "2024-12-03 21:46:17,177 - INFO - ./data/processed_ATL03_20210710170614_02601214_006_01.h5\n",
      "2024-12-03 21:46:17,186 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:46:58,999 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:46:59,000 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:46:59,054 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:46:59,055 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:46:59,151 - INFO - SUCCESS!\n",
      "2024-12-03 21:46:59,161 - INFO - ./data/processed_ATL03_20220821080545_09221614_006_01.h5\n",
      "2024-12-03 21:46:59,167 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:46:59,592 - INFO - ./data/processed_ATL03_20210709162010_02451203_006_01.h5\n",
      "2024-12-03 21:46:59,598 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt1l']\n",
      "Processing strong beam: gt1l\n",
      "Processing binning for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt1l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:47:20,595 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:47:20,595 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:47:20,701 - INFO - SUCCESS!\n",
      "2024-12-03 21:47:20,714 - INFO - ./data/processed_ATL03_20190211213415_06940206_006_02.h5\n",
      "2024-12-03 21:47:20,723 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l']\n",
      "Processing strong beam: gt1l\n",
      "Processing binning for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt1l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:47:41,862 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:47:41,863 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:47:41,958 - INFO - SUCCESS!\n",
      "2024-12-03 21:47:41,970 - INFO - ./data/processed_ATL03_20210630030952_00991206_006_01.h5\n",
      "2024-12-03 21:47:41,979 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt3l']\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:48:03,132 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:48:03,133 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:48:03,231 - INFO - SUCCESS!\n",
      "2024-12-03 21:48:03,246 - INFO - ./data/processed_ATL03_20201116164551_08170908_006_01.h5\n",
      "2024-12-03 21:48:03,252 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt2l', 'gt3l', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:48:03,649 - INFO - ./data/processed_ATL03_20200629212148_00690806_006_01.h5\n",
      "2024-12-03 21:48:03,656 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt1l', 'gt2l', 'gt3l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:49:05,539 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:49:05,539 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:49:05,549 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:49:05,550 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:49:05,604 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:49:05,604 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:49:05,689 - INFO - SUCCESS!\n",
      "2024-12-03 21:49:05,699 - INFO - ./data/processed_ATL03_20190506031153_05780308_006_02.h5\n",
      "2024-12-03 21:49:05,709 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:49:06,125 - INFO - ./data/processed_ATL03_20181213181733_11620114_006_02.h5\n",
      "2024-12-03 21:49:06,134 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1r', 'gt2r', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:49:06,527 - INFO - ./data/processed_ATL03_20210703140243_01521202_006_01.h5\n",
      "2024-12-03 21:49:06,534 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt1l', 'gt2l', 'gt3l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:50:09,315 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:50:09,315 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:50:09,371 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:50:09,372 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:50:09,427 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:50:09,427 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:50:09,471 - INFO - SUCCESS!\n",
      "2024-12-03 21:50:09,482 - INFO - ./data/processed_ATL03_20191010201542_02130502_006_02.h5\n",
      "2024-12-03 21:50:09,488 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong Beams Found: ['gt1l', 'gt2l', 'gt3l']\n",
      "Processing strong beam: gt1l\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt1l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt1l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:51:13,225 - INFO - Calculating Kd for beam: gt1l\n",
      "2024-12-03 21:51:13,225 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:51:13,290 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:51:13,291 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:51:13,352 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:51:13,353 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:51:13,429 - INFO - SUCCESS!\n",
      "2024-12-03 21:51:13,446 - INFO - ./data/processed_ATL03_20230305110600_11441803_006_02.h5\n",
      "2024-12-03 21:51:13,452 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n",
      "2024-12-03 21:51:13,876 - INFO - ./data/processed_ATL03_20200221023939_08610606_006_01.h5\n",
      "2024-12-03 21:51:13,882 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:51:14,683 - INFO - ./data/processed_ATL03_20210211090957_07541006_006_01.h5\n",
      "2024-12-03 21:51:14,693 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:51:15,355 - INFO - ./data/processed_ATL03_20190926024902_13750403_006_02.h5\n",
      "2024-12-03 21:51:15,362 - INFO - ['METADATA', 'ancillary_data', 'atlas_impulse_response', 'ds_surf_type', 'ds_xyz', 'gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Strong Beam\n",
      "Strong Beams Found: ['gt2l', 'gt3l']\n",
      "Processing strong beam: gt2l\n",
      "Processing strong beam: gt3l\n",
      "Processing binning for beam: gt2l\n",
      "Processing binning for beam: gt3l\n",
      "Processing subsurface filtering for beam: gt2l\n",
      "Processing subsurface filtering for beam: gt3l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:51:57,337 - INFO - Calculating Kd for beam: gt2l\n",
      "2024-12-03 21:51:57,338 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:51:57,350 - INFO - Calculating Kd for beam: gt3l\n",
      "2024-12-03 21:51:57,351 - INFO - Calculating Kd from filtered subsurface photon dataset\n",
      "2024-12-03 21:51:57,397 - INFO - SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "h5names = glob.glob('data/processed_*.h5')\n",
    "\n",
    "\n",
    "for jj in range(len(h5names)):\n",
    "    # code from chao (in Main.ipynb)\n",
    "    atl03_file_inloop = h5names[jj]\n",
    "    ATL03_h5_file_path = os.path.join(workspace_path, atl03_file_inloop)\n",
    "    # print(ATL03_h5_file_path)\n",
    "    shoreline_data_path = os.path.join(workspace_path, other_data_path, shoreline_data)\n",
    "    # print(shoreline_data_path)\n",
    "    GEBCO_full_path = os.path.join(workspace_path, other_data_path, gebco_path)\n",
    "    # print(GEBCO_full_path)\n",
    "    OutputPath = os.path.join(workspace_path, output_path)\n",
    "    # print(OutputPath)\n",
    "    \n",
    "    \n",
    "    #Get the gebco list\n",
    "    GEBCO_file_pattern = os.path.join(GEBCO_full_path, \"gebco_*.tif\")\n",
    "    \n",
    "    #Initialize with an empty list\n",
    "    GEBCO_file_path_lists = []\n",
    "    for GEBCO_file_path_name in glob.glob(GEBCO_file_pattern):\n",
    "        #put the find one into the list\n",
    "        GEBCO_file_path_lists.append(GEBCO_file_path_name)\n",
    "    \n",
    "    # print(GEBCO_file_path_lists)\n",
    "    \n",
    "    # Get all other necessary parameters\n",
    "    horizontal_res = horizontal_res\n",
    "    vertical_res = vertical_res\n",
    "    subsurface_thresh = subsurface_thresh\n",
    "    Ignore_Subsurface_Height_Thres = ignore_subsurface_height_thres\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    \n",
    "    # When all paramters ready, call the main function\n",
    "    main()\n",
    "    # delete the hefty h5 file once done with processing - only store calculated kd values\n",
    "    os.remove(ATL03_h5_file_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
