{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os,sys,re\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import requests, argparse\n",
    "import time\n",
    "from datetime import datetime,timedelta, date\n",
    "import matplotlib.pyplot as plt\n",
    "import ioos_mod # our very own module!\n",
    "\n",
    "# Create an arparse argument\n",
    "# If f_update is turned on (True) the fil will reload \n",
    "#regardless of if it is already a file that exists\n",
    "# This is useful if there is a timeout or error while loading\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', '--file_update', default=False, type=ooi_mod.boolean_string)\n",
    "args = parser.parse_args()\n",
    "f_update=args.file_update\n",
    "\n",
    "# # Please insert your API Username and Token here\n",
    "print('An account with for OOI data portal is required to access this data. '+\n",
    "\t'To create an account, visit: https://ooinet.oceanobservatories.org/ ')\n",
    "API_USERNAME = input('API Username: ')\n",
    "API_TOKEN = input('API Token: ')\n",
    "\n",
    "# Create an error if there is no username or token\n",
    "class LoginError(Exception):\n",
    "\tpass\n",
    "if len(API_USERNAME)==0 or len(API_TOKEN)==0:\n",
    "\tprint()\n",
    "\traise LoginError('Please input your API Username and Token')\n",
    "\n",
    "# Create an error if the time selected by the user is not useable\n",
    "class TimeError(Exception):\n",
    "\tpass\n",
    "\n",
    "# get the current working directory then only keep name up 2 levels\n",
    "# this will be used as the root for /code, /ooi_data, /ooi_output:\n",
    "dir_path = os.getcwd()\n",
    "a = dir_path.split('/') # makes a list out of the path name\n",
    "dir_name = a[-2]\n",
    "del a[-2:]# remove last two directories\n",
    "dir_path = '/'.join(a)\n",
    "\n",
    "# make an input data directory:\n",
    "in_dir = dir_path+'/'+dir_name+'_data/'\n",
    "ooi_mod.make_dir(in_dir)\n",
    "\n",
    "# make an output data directory:\n",
    "out_dir = dir_path+'/'+dir_name+'_output/'\n",
    "ooi_mod.make_dir(out_dir)\n",
    "\n",
    "# Get the station information loaded here\n",
    "st_df = pd.read_pickle('./Station_Info.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# User Selections - Stations and time range\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Print out the stations numbered for user selection\n",
    "st_sel = st_df.index\n",
    "my_choice1 = ooi_mod.list_picker('Station Selection',st_sel)\n",
    "Station = st_sel[int(my_choice1)-1]\n",
    "\n",
    "# Get all of the info for that station\n",
    "site = st_df.loc[Station]['Site']\n",
    "node = st_df.loc[Station]['Node']\n",
    "instrument = st_df.loc[Station]['Instrument']\n",
    "method = st_df.loc[Station]['Method']\n",
    "stream = st_df.loc[Station]['Stream']\n",
    "tst = st_df.loc[Station]['Start_Date']\n",
    "ted = st_df.loc[Station]['End_Date']\n",
    "\n",
    "# Have the min and max times as datetime format for that station\n",
    "station_start_time = datetime.strptime(tst[0:19],'%Y-%m-%dT%H:%M:%S')\n",
    "station_end_time = datetime.strptime(ted[0:19],'%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# Set up start and end times for a few supplied options\n",
    "tos = [[station_end_time - timedelta(days=90),station_end_time],\n",
    "[station_end_time - timedelta(days=183),station_end_time],\n",
    "[station_start_time,station_start_time + timedelta(days=183)],\n",
    "[station_start_time, station_end_time]]\n",
    "\n",
    "# Create a list for our pre-supplied options and print it to the screen for user selection\n",
    "opts = [tos[0][0].strftime('%Y-%m-%d')+' to '+tos[0][1].strftime('%Y-%m-%d')+' (Last 90 Days)',\n",
    "\t\ttos[1][0].strftime('%Y-%m-%d')+' to '+tos[1][1].strftime('%Y-%m-%d')+' (Last 6 Months)',\n",
    "\t\ttos[2][0].strftime('%Y-%m-%d')+' to '+tos[2][1].strftime('%Y-%m-%d')+' (First 6 Months)',\n",
    "\t\ttos[3][0].strftime('%Y-%m-%d')+' to '+tos[3][1].strftime('%Y-%m-%d')+' (Entire Time Series)',\n",
    "\t\t'Custom Date Range']\n",
    "\n",
    "# Print out the time options numbered for user selection\n",
    "my_choice = ooi_mod.list_picker('Time Selection',opts)\n",
    "ini = int(my_choice)\n",
    "\n",
    "# Go through the user's option saving the start and end times\n",
    "if (ini < len(opts)-1) and (ini>0):\n",
    "\tstart_time = tos[ini-1][0]\n",
    "\tend_time = tos[ini-1][1]\n",
    "\ttime_diff = end_time-start_time\n",
    "\n",
    "# Since loading the entire dataset is slow, I have put a warning in here\n",
    "elif ini == len(opts)-1:\n",
    "\tprint('\\nWarning: Using the entire time series can be slow! (Particularly for shallow stations)')\n",
    "\tchecky = input('Are you sure you want to continue y(enter)/n?')\n",
    "\tif checky.lower().startswith('y') or len(checky)==0:\n",
    "\t\tstart_time = tos[ini-1][0]\n",
    "\t\tend_time = tos[ini-1][1]\n",
    "\telse:\n",
    "\t\tprint('\\nExiting!')\n",
    "\t\tsys.exit()\n",
    "\ttime_diff = end_time-start_time\n",
    "\n",
    "# Allow for users to put in a custom date range\n",
    "elif ini == len(opts):\n",
    "\tprint('\\nPossible Time Range: ',station_start_time,' to ',station_end_time,'\\n')\n",
    "\tprint('Input Format: YYYY-mm-dd HH:MM:SS')\n",
    "\tprint('Date (YYYY-mm-dd) is required; Time (HH:MM:SS) is optional, default 00:00:00')\n",
    "\n",
    "\t# User input\n",
    "\tst_time = input('Start Time: ')\n",
    "\ted_time = input('End Time: ')\n",
    "\n",
    "\t# Make inputs into datetime objects\n",
    "\tif len(st_time)< 10 or len(ed_time)< 10:\n",
    "\t\traise TimeError('No time selected. Please try again!')\n",
    "\telif len(st_time)==10:\n",
    "\t\tstart_time = np.max([datetime.strptime(st_time[0:10].strip(),'%Y-%m-%d'),station_start_time])\n",
    "\telif len(st_time) == 19:\n",
    "\t\tstart_time = datetime.strptime(st_time.strip(),'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\tif len(ed_time)==10:\n",
    "\t\tend_time = np.min([datetime.strptime(ed_time[0:10].strip(),'%Y-%m-%d'),station_end_time])\n",
    "\telif len(ed_time) == 19:\n",
    "\t\tend_time = datetime.strptime(ed_time.strip(),'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\ttime_diff = end_time-start_time\n",
    "\n",
    "\t# If the input date range is outside of the given instrument, give an error\n",
    "\tif ((start_time-station_start_time).days < 0) or ((end_time-station_end_time).days>0):\n",
    "\t\traise TimeError('Please select a time within the given range.')\n",
    "\tprint('\\nTime Range: ',start_time,' to ',end_time,'\\n')\n",
    "\n",
    "# user inputs will be \n",
    "\n",
    "\n",
    "# Retrieving Data\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# Make the start and end times into useable strings\n",
    "start_time = start_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "end_time = end_time.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "\n",
    "# Create a file name where the data will be saved\n",
    "fname = in_dir+'/'+Station+'_'+'_'.join([start_time,end_time])+'.nc'\n",
    "\n",
    "# If this file already exists (and the user does not want to update), pull from there!\n",
    "if os.path.isfile(fname) and not f_update:\n",
    "\tprint(fname)\n",
    "\tprint('\\nDone!')\n",
    "\tds = nc.Dataset(fname)\n",
    "\t\n",
    "# Otherwise pull from the THREDDS server\n",
    "else:\n",
    "\t# Set up the parameters used in the data grab\n",
    "\tparams = {'beginDT':start_time,'endDT':end_time,\n",
    "\t  'format':'application/netcdf','include_provenance':'true','include_annotations':'false'}\n",
    "\n",
    "\t# Create the request URL\n",
    "\tapi_base_url = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv'\n",
    "\tdata_request_url ='/'.join((api_base_url,site,node,instrument,method,stream))\n",
    "\n",
    "\t# Set up changeable variables\n",
    "\turl = []\n",
    "\tfdep = False\n",
    "\n",
    "\t# Get the THREDDS server link either from our pre-made file or from the API request\n",
    "\t# Find if our THREDDS file exists already\n",
    "\tif os.path.isfile(out_dir+'/THREDDS_Servers.txt'):\n",
    "\t\t# Open the file and go through each line\n",
    "\t\twith open(out_dir+'/THREDDS_Servers.txt','r') as f:\n",
    "\t\t\tloads = f.readlines()\n",
    "\t\tdel_line = ''\n",
    "\t\tfor l in range(0,len(loads)):\n",
    "\t\t\tl_list = loads[l].split(',')\n",
    "\t\t\t# If the station, the start time, and end time are the same as user input\n",
    "\t\t\t# Also, if it has been genereated within the past 2 weeks\n",
    "\t\t\t# Use the url we already created, saved in the file\n",
    "\t\t\tif (site==l_list[1]) and (start_time==l_list[2]) and (end_time==l_list[3]):\n",
    "\t\t\t\tif (datetime.now()<datetime.strptime(l_list[4][:-1],'%Y-%m-%dT%H:%M:%S.000Z')+timedelta(days=14)):\n",
    "\t\t\t\t\turl = l_list[0]\n",
    "\t\t\t\t\tfdep = True\n",
    "\t\t\t\t\tprint('\\nTHREDDS Server URL:',url)\n",
    "\t\t\t\t# Remove the line if the link has been active for longer than 2 weeks\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdel_line = loads[l]\n",
    "\t\t# Resave the file without the old links\n",
    "\t\twith open(out_dir+'/THREDDS_Servers.txt', 'w') as f:\n",
    "\t\t\tfor line in loads:\n",
    "\t\t\t\tif line != del_line:\n",
    "\t\t\t\t\tf.write(line)\n",
    "\n",
    "\t# If the file does not exist or the url is still unfilled, get the THREDDS server using API\n",
    "\tif not os.path.isfile(out_dir+'/THREDDS_Servers.txt') or not fdep:\n",
    "\t\tr = requests.get(data_request_url, params=params, auth=(API_USERNAME, API_TOKEN))\n",
    "\t\tdata = r.json()\n",
    "\t\t# If there is a message, something has gone wrong\n",
    "\t\tif 'message' in data:\n",
    "\t\t\t# Error code 404 means that there is no data for the selected time range\n",
    "\t\t\tif 'code' in data['message'] and data['message']['code']==404:\n",
    "\t\t\t\tprint('Uh oh! No data available for this time period. Please try again!\\n')\n",
    "\t\t\t\tsys.exit()\n",
    "\t\t\t# Authentication failure means they typed in passcode wrong\n",
    "\t\t\telif 'Authentication failed' in data['message']:\n",
    "\t\t\t\tprint('Authentication failed: Please check your login credentials for typos.')\n",
    "\t\t\t\tsys.exit()\n",
    "\t\t# Get the THREDDS link\n",
    "\t\turl = data['allURLs'][0]\n",
    "\t\twith open(out_dir+'/THREDDS_Servers.txt',\"a+\") as f:\n",
    "\t\t\tf.write(','.join([url,site,start_time,end_time, datetime.now().strftime('%Y-%m-%dT%H:%M:%S.000Z')])+'\\n')\n",
    "\t\t\tprint('\\nTHREDDS Server URL:',url)\n",
    "\t# Get the datasets\n",
    "\t# We have to wait for the data to appear on the server, try every 15 seconds until it is there\n",
    "\t# Timeout after 10 minutes if they picked one of the premade options (not ful time-series)\n",
    "\tprint('\\nWaiting for data...')\n",
    "\tselected_datasets = ooi_mod.get_data(url)\n",
    "\ttic = time.time()\n",
    "\twhile len(selected_datasets) == 0:\n",
    "\t\ttime.sleep(15)\n",
    "\t\tprint('Waiting...')\n",
    "\t\tselected_datasets = ooi_mod.get_data(url)\n",
    "\t\t# Save the amount of time that has passed\n",
    "\t\ttoc = time.time() - tic\n",
    "\t\tif int(my_choice) < len(opts)-1 and toc > 600:\n",
    "\t\t\t# This is out timeout error\n",
    "\t\t\tprint('Something is wrong... Exiting now.')\n",
    "\t\t\tsys.exit()\n",
    "\n",
    "\tif not fdep:\n",
    "\t\t# If the time series is relatively short (or if there isn't much data - Deep)\n",
    "\t\t# We wait 60 extra seconds to let the data all settle in the server\n",
    "\t\tif time_diff.days<=1000 or 'Deep' in Station:\n",
    "\t\t\tprint('Initializing Dataset...')\n",
    "\t\t\ttime.sleep(90)\n",
    "\t\t\tselected_datasets = ooi_mod.get_data(url)\n",
    "\t\t# If the time series is long (>1000 days) for a shallow station\n",
    "\t\t# We wait 15 minutes for the data to settle in the server\n",
    "\t\telif time_diff.days>1000 and ('Shallow' in Station):\n",
    "\t\t\tprint('Waiting...')\n",
    "\t\t\ttime.sleep(30)\n",
    "\t\t\tprint('Initializing dataset for shallow station (15 minutes)...')\n",
    "\t\t\ttime.sleep(900)\n",
    "\t\t\tselected_datasets = ooi_mod.get_data(url)\n",
    "\n",
    "\t# Print statements!\n",
    "\tprint('Data is loaded!')\n",
    "\tprint('\\nExtracting and Saving...')\t\n",
    "\n",
    "\t# We should now be able to get all of the data into a structure using netCDF4\n",
    "\t# if len(selected_datasets) == 1:\n",
    "\tif 'Shallow' in Station:\n",
    "\t\t# Open the dataset and ignore the variables we don't need (there are a lot!)\n",
    "\t\tds1 = xr.open_mfdataset(selected_datasets,combine='nested',concat_dim='obs',drop_variables=\n",
    "\t\t\t['corrected_dissolved_oxygen','density_qc_executed','driver_timestamp',\n",
    "\t\t\t'seawater_pressure_qc_results','practical_salinity_qc_results','provenance',\n",
    "\t\t\t'corrected_dissolved_oxygen_qc_executed','corrected_dissolved_oxygen_qc_results',\n",
    "\t\t\t'seawater_temperature_qc_results','internal_timestamp','seawater_conductivity_qc_results', \n",
    "\t\t\t'ext_volt0','ingestion_timestamp','port_timestamp','seawater_pressure_qc_executed',\n",
    "\t\t\t'deployment','preferred_timestamp','practical_salinity_qc_executed','seawater_temperature_qc_executed', \n",
    "\t\t\t'density_qc_results', 'seawater_conductivity_qc_executed','pressure_temp','temperature','pressure',\n",
    "\t\t\t'seawater_conductivity','conductivity','id'])\n",
    "\n",
    "\t\t# Reformat the coordinates and rename the variables so it matches the deep stations\n",
    "\t\tds1 = ds1.reset_coords(['seawater_pressure','lon','lat','time'])\n",
    "\t\tds1 = ds1.rename({'seawater_pressure':'pressure','seawater_temperature':'temp'})\n",
    "\telif 'Deep' in Station:\n",
    "\t\t# Open the dataset and ignore the variables we don't need (there are a lot!)\n",
    "\t\tds1 = xr.open_mfdataset(selected_datasets,combine='nested',concat_dim='obs',drop_variables=\n",
    "\t\t\t['dpc_ctd_seawater_conductivity','conductivity_millisiemens','density_qc_executed',\n",
    "\t\t\t'driver_timestamp','id','practical_salinity_qc_results','provenance','internal_timestamp',\n",
    "\t\t\t'raw_time_microseconds','ingestion_timestamp','conductivity_millisiemens_qc_executed',\n",
    "\t\t\t'port_timestamp','raw_time_seconds','deployment','pressure_qc_results','pressure_qc_executed',\n",
    "\t\t\t'preferred_timestamp','temp_qc_executed','dpc_ctd_seawater_conductivity_qc_results',\n",
    "\t\t\t'practical_salinity_qc_executed','temp_qc_results','conductivity_millisiemens_qc_results',\n",
    "\t\t\t'density_qc_results','dpc_ctd_seawater_conductivity_qc_executed'])\n",
    "\n",
    "\t# Save the file\n",
    "\tdel ds1.attrs['_NCProperties'] # This is to deal with a bug with xarray\n",
    "\tif fdep:\n",
    "\t\tos.remove(fname)\n",
    "\tds1.to_netcdf(fname, mode='w')\n",
    "\tprint(fname)\n",
    "\tprint('Done!')\n",
    "\n",
    "\t# Open the file that we just saved\n",
    "\tds = nc.Dataset(fname)\n",
    "\n",
    "\n",
    "\n",
    "# Manipulating data\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# relevant fields from netcdf file\n",
    "flds = ['time','pressure','practical_salinity','temp','density']\n",
    "units = []\n",
    "fillval = []\n",
    "for jj in range (0,len(flds)):\n",
    "    units.append(ds[flds[jj]].units)\n",
    "    fillval.append(ds[flds[jj]]._FillValue)\n",
    "\n",
    "# fix the time stamp:\n",
    "t_ooi = ds[flds[0]][:] # pull out the time from the netcdf\n",
    "t_ooi[t_ooi==fillval[0]]=np.nan # nan any bad vals\n",
    "if '1900' in units[0]: # there are two options for the reference year for the OOI time: 1900,1970\n",
    "    t0=datetime.toordinal(date(1900,1,1))\n",
    "elif '1970' in units[0]:\n",
    "    t0=datetime.toordinal(date(1970,1,1))\n",
    "\n",
    "# use this function to convert to a python datetime\n",
    "tt =[]\n",
    "for jj in range(0,len(t_ooi)):\n",
    "    tt.append(ooi_mod.ooi_to_datetime(t_ooi[jj],t0))\n",
    "\n",
    "\n",
    "# put the data into a pandas data frame for convenient storage\n",
    "df = pd.DataFrame(data=tt,columns=[flds[0]])\n",
    "for jj in range (1,len(flds)):\n",
    "    temp = ds[flds[jj]][:] #pull out data\n",
    "    temp[temp==fillval[jj]]=np.nan # nan any bad vals\n",
    "    df.insert(jj,flds[jj],ds[flds[jj]][:])\n",
    "\n",
    "# set the time (first col) as index:\n",
    "df.set_index('time',inplace=True)\n",
    "\n",
    "# switch the .nc name to a pickle name and save in the output directory:\n",
    "fname=fname.replace('nc','p')\n",
    "# save the dataframe as a pickle file\n",
    "df.to_pickle(fname)\n",
    "print('Done saving pickle file of pandas dataframe!')\n",
    "# # save the metadata as a pickle file:\n",
    "# pickle.dump(units, open('meta_'+save_name, 'wb')) # 'wb' is for write binary\n",
    "\n",
    "\n",
    "# Plotting initial!\n",
    "# plt.close('all')\n",
    "\n",
    "# fig = plt.figure() \n",
    "# ax1 = fig.add_subplot(111)\n",
    "# xx = ax1.scatter(ds['time'],ds['seawater_pressure'],c=ds['seawater_temperature']) \n",
    "# ax1.invert_yaxis()\n",
    "# plt.colorbar(xx,label='Temperature (degC)')\n",
    "# ax1.set_xlabel('Time')\n",
    "# ax1.set_ylabel('Pressure (dbar)')\n",
    "# ax1.set_xlim([np.nanmin(ds['time']),np.nanmax(ds['time'])])\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
