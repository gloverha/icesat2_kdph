{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ee7b13-ffc0-4421-97cb-d0521eda0e26",
   "metadata": {},
   "source": [
    "Goal: pull out 1 buoy record that has ssc&chla and search for matching icesat2 granules\n",
    "\n",
    "To do:\n",
    "- Load info for 1 relevant station\n",
    "- Find all matching atl granules and save times from file names\n",
    "- Compare times to see if any matching buoy times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ac0bb6-2b05-466a-b79e-2ca653da7401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet erddapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950557e2-e65e-41e4-9e4e-e74111ba592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client (version (4, 5, 3)) is out of date with the server (version (4, 6, 2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from erddapy import ERDDAP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sliderule import sliderule, icesat2, earthdata\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "sliderule.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65db29b3-ac6e-44bb-a73c-65eb4949880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname2datetime(fname):\n",
    "    y = int(fname[6:10])\n",
    "    m = int(fname[10:12])\n",
    "    d = int(fname[12:14])\n",
    "    H = int(fname[14:16])\n",
    "    M = int(fname[16:18])\n",
    "    S = int(fname[18:20])\n",
    "\n",
    "    t = datetime(y,m,d,H,M,S, tzinfo=timezone.utc)\n",
    "    return t\n",
    "\n",
    "def buoy_bound_box(lat,lon,buffer_km):\n",
    "    # define a buffer distance around the buoy to search for icesat-2 data\n",
    "    lat_buff = buffer_km/111 # convert buffer distance to frac of 1 deg lat\n",
    "    lon_buff = buffer_km/(111*np.cos(lat*np.pi/180)) # convert buffer distance to frac of 1 deg lon\n",
    "    # define bounding box around the buoy (WSEN)\n",
    "    # example: bbox = [-108.3, 39.2, -107.8, 38.8]\n",
    "    # bbox = [lon-lon_buff,lat+lat_buff,lon+lon_buff,lat-lat_buff]\n",
    "    # region = sliderule.toregion(bbox)\n",
    "    minx = lon - lon_buff\n",
    "    miny = lat - lat_buff\n",
    "    maxx = lon + lon_buff\n",
    "    maxy = lat + lat_buff\n",
    "\n",
    "    poly = [{'lon': minx, 'lat': miny},\n",
    "            {'lon': maxx, 'lat': miny},\n",
    "            {'lon': maxx, 'lat': maxy},\n",
    "            {'lon': minx, 'lat': maxy},\n",
    "            {'lon': minx, 'lat': miny}] # Closing the loop by repeating the first point\n",
    "    return poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ae2ffe-83e8-48bb-924d-5d8ef3abd1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search for all possible station\n",
    "e = ERDDAP(\n",
    "    server='https://erddap-goldcopy.dataexplorer.oceanobservatories.org/erddap/', \n",
    "    protocol=\"tabledap\", # Want table data (not a grid map of data) \n",
    "    response=\"csv\") #in csv format for pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6e63a9-1227-4a63-8c04-3b1f59e24d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_210/2334841492.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-42.92283' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  FF.loc[jj,\"lat\"] = df.loc[df['Attribute Name']=='lat', 'Value'].item()\n",
      "/tmp/ipykernel_210/2334841492.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-42.4393' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  FF.loc[jj,\"lon\"] = df.loc[df['Attribute Name']=='lon', 'Value'].item()\n"
     ]
    }
   ],
   "source": [
    "# dont run this cell if you can just load \"all_endurance_array_sites\"\n",
    "search_url = e.get_search_url(search_for='radiation', response=\"csv\")# search for a match to our time\n",
    "temp = pd.read_csv(search_url)[\"Dataset ID\"].unique() # try to save the data\n",
    "# # make a df for all the possible sites, with time, lat and lon\n",
    "FF = pd.DataFrame(temp,columns=['sites'])\n",
    "FF[\"time_coverage_start\"] = ''\n",
    "FF[\"time_coverage_end\"] = ''\n",
    "FF[\"lat\"] = np.nan\n",
    "FF[\"lon\"] = np.nan\n",
    "FF[\"check_sum\"] = 1\n",
    "\n",
    "for jj in range(len(FF)):\n",
    "    if jj % 1000 ==0:\n",
    "        print(jj)# give a printout every 1000 for my sanity\n",
    "    \n",
    "    # make the info URL for this site for this time range\n",
    "    e.dataset_id = FF['sites'][jj]\n",
    "    info_url = e.get_info_url()\n",
    "\n",
    "    # make a dataframe for all the metadata for this station\n",
    "    # some of these urls are bogus - if fail then fill with NaNs\n",
    "    try:\n",
    "        df = pd.read_csv(info_url)# make a dataframe for all the metadata for this station\n",
    "    except:\n",
    "        FF.loc[jj,\"check_sum\"] = np.nan\n",
    "        continue\n",
    "\n",
    "    # some metadata is missing - leave blank if any is empty\n",
    "    try:\n",
    "        FF.loc[jj,\"time_coverage_start\"] = df.loc[df['Attribute Name']=='time_coverage_start', 'Value'].item()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        FF.loc[jj,\"time_coverage_end\"] = df.loc[df['Attribute Name']=='time_coverage_end', 'Value'].item()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        FF.loc[jj,\"lat\"] = df.loc[df['Attribute Name']=='lat', 'Value'].item()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        FF.loc[jj,\"lon\"] = df.loc[df['Attribute Name']=='lon', 'Value'].item()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "FF = FF.dropna(subset=\"check_sum\")  \n",
    "FF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# only look at sites with GPS location\n",
    "FF[\"lat\"] = pd.to_numeric(FF[\"lat\"])\n",
    "FF[\"lon\"] = pd.to_numeric(FF[\"lon\"])\n",
    "FF = FF[~np.isnan(FF['lat'])]\n",
    "FF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "FF.to_pickle('all_endurance_array_sites_radiation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2838f328-5d3f-42ae-94f1-4e9886c9596b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FF = pd.read_pickle('all_endurance_array_sites_radiation')\n",
    "\n",
    "len(FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b14d3-5c29-41db-8b18-8baec3bed70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each buoy asset:\n",
    "for jj in range(10):\n",
    "    # define a search region around the buoy \n",
    "    lat = FF['lat'][jj]\n",
    "    lon = FF['lon'][jj]\n",
    "    poly = buoy_bound_box(lat,lon,0.1)\n",
    "\n",
    "    # search CMR for ATL03 granules in the bounding box\n",
    "    grns = earthdata.cmr(short_name=\"ATL03\",\n",
    "                         polygon=poly,\n",
    "                         version='006')\n",
    "    # save the times for each granule as a datetime object\n",
    "    icesat_times = [fname2datetime(fname) for fname in grns]\n",
    "\n",
    "    # now check if buoy data exists for these granules\n",
    "    e.dataset_id = FF['sites'][jj]\n",
    "\n",
    "    for t in icesat_times:\n",
    "        # add a time buffer (+/-1 hours) to search for relevant buoy data for each granule,\n",
    "        t_start = (t-timedelta(hours=1)).strftime(\"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        t_end = (t+timedelta(hours=1)).strftime(\"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        e.constraints = {\"time>=\": t_start,\n",
    "                        \"time<=\": t_end}\n",
    "\n",
    "        # try to download the associated buoy data\n",
    "        try:\n",
    "            buoy = e.to_pandas(parse_dates=True)\n",
    "        except:\n",
    "            continue\n",
    "        # if buoy data exists, download the ATL03 photons in the bounding box at this time\n",
    "        print('downloading ATL03 for '+ e.dataset_id + ' ' + str(t_start))\n",
    "        # Build ATL03 Request\n",
    "        poly = buoy_bound_box(lat,lon,1)\n",
    "        parms = {\"poly\": poly,\n",
    "                 \"t0\": t_start,\n",
    "                 \"t1\": t_end,\n",
    "                 \"srt\": icesat2.SRT_OCEAN,\n",
    "                 \"track\": 1,\n",
    "                 \"beam\": 'gt1l',\n",
    "                }      \n",
    "        atl_gdb = icesat2.atl03sp(parms)\n",
    "        print('no. of photons: '+len(atl_gdb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
