{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141611e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "# help(ERDDAP.get_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat this:\n",
    "# search for any data set within a small time and space window\n",
    "# get info for each - \n",
    "# check variable names for those key words\n",
    "# download that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73dc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of setting time/space search criteria\n",
    "\n",
    "\n",
    "# kw = {\n",
    "#     \"min_lon\": -72.0,\n",
    "#     \"max_lon\": -69.0,\n",
    "#     \"min_lat\": 3f8.0,\n",
    "#     \"max_lat\": 41.0,\n",
    "#     \"min_time\": \"2016-07-10T00:00:00Z\",\n",
    "#     \"max_time\": \"2017-02-10T00:00:00Z\",\n",
    "# }\n",
    "# search_url = e.get_search_url(response=\"html\", **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1888b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keywrds = ['par','photon','radiance','downwelling','turbidity','sediment','ssc','cdom','chlorophyll']\n",
    "\n",
    "min_time = \"2024-01-01T00:00:00Z\"\n",
    "max_time = \"2024-01-02T00:00:00Z\"\n",
    "kw = {\n",
    "    \"min_lon\": -170.0,\n",
    "    \"max_lon\": -43.0,\n",
    "    \"min_lat\": 2.0,\n",
    "    \"max_lat\": 80.0,\n",
    "    \"min_time\": min_time,\n",
    "    \"max_time\": max_time,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ccb9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_search_url in module erddapy.erddapy:\n",
      "\n",
      "get_search_url(response: Optional[str] = None, search_for: Optional[str] = None, protocol: Optional[str] = None, items_per_page: int = 1000, page: int = 1, **kwargs) -> str method of erddapy.erddapy.ERDDAP instance\n",
      "    Build the search URL for the `server` endpoint provided.\n",
      "    \n",
      "    Args:\n",
      "        search_for: \"Google-like\" search of the datasets' metadata.\n",
      "    \n",
      "            - Type the words you want to search for, with spaces between the words.\n",
      "                ERDDAP will search for the words separately, not as a phrase.\n",
      "            - To search for a phrase, put double quotes around the phrase\n",
      "                (for example, `\"wind speed\"`).\n",
      "            - To exclude datasets with a specific word, use `-excludedWord`.\n",
      "            - To exclude datasets with a specific phrase, use `-\"excluded phrase\"`\n",
      "            - Searches are not case-sensitive.\n",
      "            - You can search for any part of a word. For example,\n",
      "                searching for `spee` will find datasets with `speed` and datasets with\n",
      "                `WindSpeed`\n",
      "            - The last word in a phrase may be a partial word. For example,\n",
      "                to find datasets from a specific website (usually the start of the datasetID),\n",
      "                include (for example) `\"datasetID=erd\"` in your search.\n",
      "    \n",
      "        response: default is HTML.\n",
      "        items_per_page: how many items per page in the return,\n",
      "            default is 1000 for HTML, 1e6 (hopefully all items) for CSV, JSON.\n",
      "        page: which page to display, default is the first page (1).\n",
      "        kwargs: extra search constraints based on metadata and/or coordinates ke/value.\n",
      "            metadata: `cdm_data_type`, `institution`, `ioos_category`,\n",
      "            `keywords`, `long_name`, `standard_name`, and `variableName`.\n",
      "            coordinates: `minLon`, `maxLon`, `minLat`, `maxLat`, `minTime`, and `maxTime`.\n",
      "    \n",
      "    Returns:\n",
      "        url: the search URL.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(e.get_search_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2677e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching http://www.neracoos.org/erddapfor photon\n",
      "----no matching sites exist\n",
      "Searching http://www.neracoos.org/erddapfor radiance\n",
      "----no matching sites exist\n",
      "Searching http://www.neracoos.org/erddapfor downwelling\n",
      "----no matching sites exist\n",
      "Searching http://www.neracoos.org/erddapfor turbidity\n",
      "36\n",
      "Searching http://www.neracoos.org/erddapfor sediment\n",
      "----no matching sites exist\n",
      "Searching http://www.neracoos.org/erddapfor ssc\n",
      "----no matching sites exist\n",
      "Searching http://www.neracoos.org/erddapfor cdom\n",
      "1\n",
      "Searching http://www.neracoos.org/erddapfor chlorophyll\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# try searching for all the variables at just one erddap server\n",
    "e = ERDDAP(\n",
    "    server=\"http://www.neracoos.org/erddap/\", \n",
    "    protocol=\"tabledap\", \n",
    "    response=\"csv\")\n",
    "\n",
    "\n",
    "allsites = list()\n",
    "for val in search_keywrds:\n",
    "    print('Searching ' + e.server + ' for ' + val)\n",
    "    url = e.get_search_url(search_for=val, response=\"csv\", **kw)\n",
    "    try:\n",
    "        temp = pd.read_csv(url)[\"Dataset ID\"].unique()\n",
    "    except:\n",
    "        print(\"----no matching sites exist\")\n",
    "    else:\n",
    "        allsites.extend(temp)\n",
    "\n",
    "FF = pd.DataFrame(allsites,columns=['sites'])\n",
    "FF = FF['sites'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df01372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A01_optics_s_all' 'E01_sbe37_all' 'F01_sbe37_all' 'M01_suna_all'\n",
      " 'A01_sbe37_all' 'B01_sbe37_all' 'A01_doppler_rt' 'I01_sbe37_all'\n",
      " 'M01_sbe37_all' 'M01_accelerometer_all' 'E01_aanderaa_all'\n",
      " 'B01_doppler_rt' 'M01_aanderaa_all' 'A01_sbe16_disox_all'\n",
      " 'A01_aanderaa_o2_all' 'A01_optode_all' 'A01_met_all' 'F01_met_all'\n",
      " 'M01_met_all' 'I01_met_all' 'B01_met_all' 'A01_waves_mstrain_all'\n",
      " 'F01_waves_mstrain_all' 'E01_waves_mstrain_all' 'M01_waves_mstrain_all'\n",
      " 'I01_waves_mstrain_all' 'B01_waves_mstrain_all' 'E01_met_all'\n",
      " 'F01_aanderaa_all' 'F01_accelerometer_all' 'B01_aanderaa_all'\n",
      " 'B01_accelerometer_all' 'I01_accelerometer_all' 'E01_accelerometer_all'\n",
      " 'I01_aanderaa_all' 'A01_accelerometer_all']\n"
     ]
    }
   ],
   "source": [
    "print(FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a39b37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['station', 'mooring_site_desc', 'time', 'chlorophyll', 'chlorophyll_qc',\n",
      "       'turbidity', 'turbidity_qc', 'longitude', 'latitude', 'depth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "e.dataset_id = FF[0]\n",
    "e.constraints = {\n",
    "    \"time>=\": min_time,\n",
    "    \"time<=\": max_time}\n",
    "\n",
    "url = e.get_download_url()\n",
    "\n",
    "df = pd.read_csv(url,parse_dates=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97838e06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# info_url = e.get_info_url(dataset_id=FF[0])\n",
    "# df = pd.read_csv(info_url)\n",
    "# print(df)\n",
    "# print((df.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
